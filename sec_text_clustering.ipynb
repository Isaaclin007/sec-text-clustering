{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling on SEC 10-k Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords as sw\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from utils.processing import scrape_edgar, format_text, lem_and_stem, add_bigrams\n",
    "from utils.stopwords import stopwords as custom_sw\n",
    "from utils.analysis import cluster_companies_by_main_topic\n",
    "\n",
    "from data.sec_edgar_urls import URLS_10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(sw.words('english')).union(custom_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Text from Edgar ##\n",
    "\n",
    "Using the URLs to the latest 10-k filings of 32 large cap companies, we scrape the SEC Edgar database to retrieve the documents in HTML format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:32<00:00,  7.37s/it]\n"
     ]
    }
   ],
   "source": [
    "docContents = scrape_edgar(URLS_10K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10-k Document Sample\n",
    "\n",
    "Here is a sample title page and table of contents for Apple's 10-k form for the 2018 fiscal year.\n",
    "\n",
    "![title](data/images/Title.png)\n",
    "\n",
    "![title](data/images/TableOfContents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure & Navigating the Documents ####\n",
    "\n",
    "While individual reports may vary between companies or fiscal years, the structure displayed in the table of contents seems to generalize across documents. We therefore use the header sections as a way to navigate the HTML document during text scraping.\n",
    "\n",
    "#### Relevant Text ####\n",
    "\n",
    "Furthermore, since the majority of the document is concerned with legal text which isn't very informative about the company's products, we discard all text except for the text *Business* header. This sections contains data like company description, their market and a list of their products.\n",
    "\n",
    "#### Failed Scrapes ####\n",
    "\n",
    "Since this is a prototype, and we are not looking for robustness, we cut our losses and discard all documents for which the our scraper failed to get text from the relevant sections. The initial 32 companies are then reduced to 15, which are Alphabet, Amazon, Apple, Chevron, Cisco, Disney, Facebook, Homedepot, Mastercard, Merck, Pfizer, Philip Morris, United Health Group, Visa and Walmart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing ##\n",
    "\n",
    "For each document we normalize the text, remove stopwords, add POS tagging and lemmatize and stem the tokens. Furthermore, since nouns are most indicative of the topic, we keep only tokens which were tagged as nouns. We also decide to only add words to our dictionary which appear 5 times or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "companies = []\n",
    "for company, doc in docContents.items():\n",
    "    companies.append(company)\n",
    "    X.append(lem_and_stem(format_text(doc), stopwords))\n",
    "X = add_bigrams(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idWordDictionary = corpora.Dictionary(X)\n",
    "idWordDictionary.filter_extremes(no_below=5)  # filter rare words\n",
    "corpus = [idWordDictionary.doc2bow(doc) for doc in X]\n",
    "readableCorpus = [[(idWordDictionary[wordid], freq) for wordid, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling ##\n",
    "\n",
    "We will now empirically determine groups of companies by performing topic modelling on the 10-k form corpus. The idea is that if two companies have the same product or market, the words they use to describe their products in the 10-k form will be similar. Peer groups can then be inferred by looking at the topic allocation for each document / company. Latent Dirichlet Association is a great way to agnostically model topics. It also provides us with a set of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTopics = 5\n",
    "passes = 1000\n",
    "seed = 667  # random.randint(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=idWordDictionary,\n",
    "    num_topics=numTopics, \n",
    "    passes=passes,\n",
    "    eta='auto',\n",
    "    alpha='auto',\n",
    "    update_every=0,  # batch learning\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we ran the model, let's have a look at how the companies group by sorting them into their most relevant topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies clustered by their most relevant topic association: \n",
      "\n",
      "{0: ['CHEVRON', 'HOMEDEPOT'],\n",
      " 1: ['UNITEDHEALTH', 'PFIZER', 'MERCK'],\n",
      " 2: ['APPLE', 'WALMART', 'AMAZON', 'CISCO', 'DISNEY'],\n",
      " 3: ['VISA', 'MASTERCARD'],\n",
      " 4: ['FACEBOOK', 'ALPHABET', 'PHILIPMORRIS']}\n"
     ]
    }
   ],
   "source": [
    "cluster = cluster_companies_by_main_topic(lda, numTopics, corpus, companies)\n",
    "print(\"Companies clustered by their most relevant topic association: \\n\")\n",
    "pprint(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of odd balls, which is expected in this small sample. For example, it isn't obvious why Philip Morris is more similar to Facebook or Alphabet than to drug or health companies like United, Pfizer or Merck. \n",
    "\n",
    "That being said, generally, similar companies seem to group together. For eaxmple, group 3 is payment providers, 1 is health / drug companies, 2 and 4 seem to be tech companies (where two seems to have tech companies that also have physical locations.\n",
    "\n",
    "To get an idea of the interpretation of the topics, we can view the words the LDA algorithm associates with each topic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words associated with each topic: \n",
      "\n",
      "[(0,\n",
      "  '0.079*\"field\" + 0.059*\"well\" + 0.051*\"home\" + 0.044*\"affili\" + '\n",
      "  '0.028*\"capac\" + 0.028*\"energi\" + 0.022*\"australia\" + 0.020*\"water\" + '\n",
      "  '0.017*\"mexico\" + 0.015*\"sharehold\"'),\n",
      " (1,\n",
      "  '0.116*\"care\" + 0.033*\"phase\" + 0.022*\"insur\" + 0.020*\"adult\" + '\n",
      "  '0.017*\"agenc\" + 0.014*\"japan\" + 0.014*\"coverag\" + 0.014*\"rule\" + '\n",
      "  '0.014*\"section\" + 0.013*\"contract\"'),\n",
      " (2,\n",
      "  '0.036*\"station\" + 0.023*\"cloud\" + 0.020*\"home\" + 0.019*\"video\" + '\n",
      "  '0.018*\"execut\" + 0.015*\"enterpris\" + 0.014*\"hardwar\" + 0.014*\"hour\" + '\n",
      "  '0.014*\"game\" + 0.013*\"shop\"'),\n",
      " (3,\n",
      "  '0.058*\"institut\" + 0.056*\"card\" + 0.040*\"issuer\" + 0.028*\"fee\" + '\n",
      "  '0.028*\"commerc\" + 0.028*\"core\" + 0.028*\"credit\" + 0.021*\"accept\" + '\n",
      "  '0.016*\"fund\" + 0.015*\"jurisdict\"'),\n",
      " (4,\n",
      "  '0.019*\"cloud\" + 0.017*\"hardwar\" + 0.016*\"video\" + 0.013*\"learn\" + '\n",
      "  '0.012*\"climat\" + 0.012*\"execut\" + 0.011*\"trend\" + 0.011*\"disclosur\" + '\n",
      "  '0.011*\"oblig\" + 0.011*\"instanc\"')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Words associated with each topic: \\n\")\n",
    "pprint(lda.print_topics())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
